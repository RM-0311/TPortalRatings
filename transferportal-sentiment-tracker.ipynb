{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install cfbd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:39:57.856665Z","iopub.execute_input":"2025-04-04T22:39:57.859547Z","iopub.status.idle":"2025-04-04T22:40:06.047940Z","shell.execute_reply.started":"2025-04-04T22:39:57.859400Z","shell.execute_reply":"2025-04-04T22:40:06.045981Z"}},"outputs":[{"name":"stdout","text":"Collecting cfbd\n  Downloading cfbd-5.6.9-py3-none-any.whl.metadata (736 bytes)\nRequirement already satisfied: urllib3<3.0.0,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from cfbd) (2.3.0)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from cfbd) (2.9.0.post0)\nCollecting pydantic<2,>=1.10.5 (from cfbd)\n  Downloading pydantic-1.10.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting aenum (from cfbd)\n  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.10.5->cfbd) (4.12.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->cfbd) (1.17.0)\nDownloading cfbd-5.6.9-py3-none-any.whl (233 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: aenum, pydantic, cfbd\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.11.0a2\n    Uninstalling pydantic-2.11.0a2:\n      Successfully uninstalled pydantic-2.11.0a2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nalbumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.21 which is incompatible.\ngoogle-genai 0.2.2 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.21 which is incompatible.\nlangchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\nlangchain 0.3.12 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.21 which is incompatible.\nlangchain-core 0.3.25 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.21 which is incompatible.\nsigstore 3.6.1 requires pydantic<3,>=2, but you have pydantic 1.10.21 which is incompatible.\nsigstore-rekor-types 0.0.18 requires pydantic[email]<3,>=2, but you have pydantic 1.10.21 which is incompatible.\nwandb 0.19.1 requires pydantic<3,>=2.6, but you have pydantic 1.10.21 which is incompatible.\nydata-profiling 4.12.2 requires pydantic>=2, but you have pydantic 1.10.21 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aenum-3.1.15 cfbd-5.6.9 pydantic-1.10.21\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import cfbd\nimport os\nimport json\nfrom datetime import datetime\nfrom kaggle_secrets import UserSecretsClient\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport time  # For adding delays","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:40:24.820312Z","iopub.execute_input":"2025-04-04T22:40:24.820788Z","iopub.status.idle":"2025-04-04T22:40:24.827677Z","shell.execute_reply.started":"2025-04-04T22:40:24.820749Z","shell.execute_reply":"2025-04-04T22:40:24.825690Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"url = \"https://247sports.com/season/2025-football/transferportal/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:40:27.214427Z","iopub.execute_input":"2025-04-04T22:40:27.214893Z","iopub.status.idle":"2025-04-04T22:40:27.220168Z","shell.execute_reply.started":"2025-04-04T22:40:27.214860Z","shell.execute_reply":"2025-04-04T22:40:27.218780Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def scrape_for_players(url, delay=1):  # Added delay parameter\n    \"\"\"\n    Scrapes player data from the 247Sports transfer portal, handling pagination and rate limiting.\n\n    Args:\n        url (str): The starting URL of the transfer portal page.\n        delay (int, optional): The delay (in seconds) between requests. Defaults to 1 second.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the scraped player data.\n    \"\"\"\n\n    all_players_data = []\n    page_num = 1\n    more_pages = True\n\n    while more_pages:\n        try:\n            current_url = f\"{url}?page={page_num}\" if page_num > 1 else url\n            print(f\"Scraping: {current_url}\")  # For debugging\n            response = requests.get(current_url)\n            response.raise_for_status()\n\n            soup = BeautifulSoup(response.content, \"html.parser\")\n            player_containers = soup.find_all(class_=\"transfer-player\")\n\n            for container in player_containers:\n                name_element = container.find(\"h3\")\n                school_logo_link = container.find(class_=\"logo source\")\n                origin_school = school_logo_link.get(\"alt\") if school_logo_link else \"NA\"\n                destination_logo_link = container.find(class_=\"logo\")\n                destination_school = destination_logo_link.get(\"alt\") if destination_logo_link else \"NA\"\n                rating_element = container.find(class_=\"rating\")\n                stars_element = container.find(class_=\"stars\")\n\n                name = name_element.text.strip() if name_element else \"NA\"\n                stars = stars_element.text.strip() if stars_element else \"NA\"\n                rating = rating_element.text.strip() if rating_element else \"NA\"\n\n                all_players_data.append({\n                    \"Name\": name,\n                    \"Origin\": origin_school,\n                    \"Destination\": destination_school,\n                    \"Stars\": stars,\n                    \"Rating\": rating,\n                })\n\n            # Check for \"Load More\" button \n            load_more_button = soup.find(class_=\"action-button transfer-group-loadMore\") \n            if load_more_button:\n                page_num += 1\n            else:\n                more_pages = False\n\n            time.sleep(delay)  # Respect rate limits\n\n        except requests.exceptions.RequestException as e:\n            print(f\"Error fetching page {page_num}: {e}\")\n            more_pages = False  # Stop scraping on error\n        except Exception as e:\n            print(f\"An error occurred on page {page_num}: {e}\")\n            more_pages = False\n\n    return pd.DataFrame(all_players_data)\n\n## NOT TODO: THIS PROJECT HAS SADLY BEEN RELEGATED TO THE DEPTHS OF TARTARUS AS MESSAGEBOARDS DO NOT ALLOW WEBSCRAPING :(","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:40:29.830910Z","iopub.execute_input":"2025-04-04T22:40:29.831360Z","iopub.status.idle":"2025-04-04T22:40:29.843286Z","shell.execute_reply.started":"2025-04-04T22:40:29.831328Z","shell.execute_reply":"2025-04-04T22:40:29.841718Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"player_data_df = scrape_for_players(url)\n\nif not player_data_df.empty:\n    print(player_data_df.head())\n    print(player_data_df.info())\nelse:\n    print(\"No player data scraped.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:40:35.116494Z","iopub.execute_input":"2025-04-04T22:40:35.116873Z","iopub.status.idle":"2025-04-04T22:40:35.188097Z","shell.execute_reply.started":"2025-04-04T22:40:35.116848Z","shell.execute_reply":"2025-04-04T22:40:35.186652Z"}},"outputs":[{"name":"stdout","text":"Scraping: https://247sports.com/season/2025-football/transferportal/\nError fetching page 1: 403 Client Error: Forbidden for url: https://247sports.com/season/2025-football/transferportal/\nNo player data scraped.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# # Get API key from Kaggle Secrets\n# user_secrets = UserSecretsClient()\n# api_key = user_secrets.get_secret(\"CFBD KEY\")\n\n# # Configure API client with explicit authorization header\n# configuration = cfbd.Configuration()\n\n# # Create API instances with explicit authorization header\n# players_api = cfbd.PlayersApi(\n#     cfbd.ApiClient(configuration, header_name='Authorization', header_value=f'Bearer {api_key}'))\n# metrics_api = cfbd.MetricsApi(\n#     cfbd.ApiClient(configuration, header_name='Authorization', header_value=f'Bearer {api_key}'))\n\n# def fetch_transfer_portal_data(year=2024):\n#     \"\"\"Fetches transfer portal data for a given year.\"\"\"\n#     try:\n#         api_response = players_api.get_transfer_portal(year=year)\n#         return api_response\n#     except cfbd.ApiException as e:\n#         print(f\"Exception when calling PlayersApi->get_transfer_portal: {e}\")\n#         return None\n\n\n# def fetch_player_season_ppa_data(year=2024, player_id=None):\n#     \"\"\"Fetches player season PPA data for a given year and player ID.\"\"\"\n#     try:\n#         if player_id is not None:\n#             api_response = metrics_api.get_player_season_ppa(year=year, player_id=player_id)\n#         else:\n#             api_response = metrics_api.get_player_season_ppa(year=year)\n#         return api_response\n#     except cfbd.ApiException as e:\n#         print(f\"Exception when calling MetricsApi->get_player_season_ppa: {e}\")\n#         return None\n\n\n# def fetch_player_id(first_name, last_name, origin, year=2024):\n#     \"\"\"Fetches player ID using player search API.\"\"\"\n#     try:\n#         search_term = f\"{first_name} {last_name}\"\n#         api_response = players_api.search_players(search_term, team=origin, year=year)\n#         if api_response and len(api_response) > 0:\n#             return api_response[0].id  # Return the first matching player's ID\n#         return None\n#     except cfbd.ApiException as e:\n#         print(f\"Exception when calling PlayersApi->search_players: {e}\")\n#         return None\n\n\n# def save_data_to_json(data, filename):\n#     \"\"\"Saves data to a JSON file in Kaggle's working directory.\"\"\"\n\n#     if data:\n\n#         def convert_datetime(obj):\n#             if isinstance(obj, datetime):\n#                 return obj.isoformat()\n#             return obj\n\n#         filepath = os.path.join(\"/kaggle/working/\", filename)\n#         with open(filepath, \"w\") as f:\n#             json.dump(\n#                 [json.loads(json.dumps(obj.to_dict(), default=convert_datetime)) for obj in data],\n#                 f,\n#                 indent=4,\n#             )\n#         print(f\"Data saved to {filepath}\")\n\n\n# def create_transfer_dataframe(portal_data):\n#     \"\"\"Creates a Pandas DataFrame from the transfer portal data.\"\"\"\n#     if portal_data:\n#         transfers = []\n#         for player in portal_data:\n#             transfers.append({\n#                 'firstName': player.firstName,\n#                 'lastName': player.lastName,\n#                 'origin': player.origin,\n#                 'stars': player.stars,\n#             })\n#         return pd.DataFrame(transfers)\n#     return pd.DataFrame()  # Return an empty DataFrame if no data\n\n\n# def add_ppa_to_dataframe(transfer_df):\n#     \"\"\"Adds PPA data to the transfer DataFrame.\"\"\"\n#     ppa_data = []\n#     for index, row in transfer_df.iterrows():\n#         try:\n#             player_id = fetch_player_id(\n#                 first_name=row['firstName'],\n#                 last_name=row['lastName'],\n#                 origin=row['origin'],\n#             )\n#             if player_id:\n#                 time.sleep(1)  # Increase delay to 1 second\n#                 player_ppa_data = metrics_api.get_player_season_ppa(player_id=player_id)\n#                 if player_ppa_data and player_ppa_data:\n#                     # Assuming player_ppa_data is a list, take the first element if available\n#                     ppa = player_ppa_data[0].ppa if player_ppa_data and player_ppa_data[0].ppa else None\n#                     transfer_df.loc[index, 'ppa'] = ppa\n#             else:\n#                 print(\n#                     f\"No matching player found for {row['firstName']} {row['lastName']} from {row['origin']}\"\n#                 )\n#         except cfbd.ApiException as e:\n#             print(f\"API Exception: {e}\")\n#             time.sleep(10)  # Wait longer after an exception\n#     return transfer_df\n\n\n# # Fetch transfer portal data\n# portal_data = fetch_transfer_portal_data()\n\n# if portal_data:\n#     transfer_df = create_transfer_dataframe(portal_data)\n#     print(transfer_df.head())\n#     transfer_df = add_ppa_to_dataframe(transfer_df)\n#     print(transfer_df.head())\n# else:\n#     print(\"Failed to fetch transfer portal data. Exiting.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:40:08.472999Z","iopub.status.idle":"2025-04-04T22:40:08.473309Z","shell.execute_reply":"2025-04-04T22:40:08.473179Z"}},"outputs":[],"execution_count":null}]}